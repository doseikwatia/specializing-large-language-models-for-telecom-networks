{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "ROOT_DIR = osp.dirname(os.getcwd())\n",
    "sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"graphrag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_community.llms.llamafile import Llamafile\n",
    "\n",
    "from lib.documents import load_documents\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENT_PATH='../data/rel18/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = load_documents(DOCUMENT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
    "She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
    "Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
    "She was, in 1906, the first woman to become a professor at the University of Paris.\n",
    "\"\"\"\n",
    "documents = [Document(page_content=text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Llamafile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m llm_transformer \u001b[38;5;241m=\u001b[39m LLMGraphTransformer(llm\u001b[38;5;241m=\u001b[39mllm)\n\u001b[0;32m----> 2\u001b[0m graph_documents \u001b[38;5;241m=\u001b[39m llm_transformer\u001b[38;5;241m.\u001b[39mconvert_to_graph_documents(documents)\n",
      "File \u001b[0;32m~/anaconda3/envs/yolo/lib/python3.11/site-packages/langchain_experimental/graph_transformers/llm.py:751\u001b[0m, in \u001b[0;36mLLMGraphTransformer.convert_to_graph_documents\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_graph_documents\u001b[39m(\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28mself\u001b[39m, documents: Sequence[Document]\n\u001b[1;32m    741\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[GraphDocument]:\n\u001b[1;32m    742\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a sequence of documents into graph documents.\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \n\u001b[1;32m    744\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;124;03m        Sequence[GraphDocument]: The transformed documents as graphs.\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response(document) \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m documents]\n",
      "File \u001b[0;32m~/anaconda3/envs/yolo/lib/python3.11/site-packages/langchain_experimental/graph_transformers/llm.py:751\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_graph_documents\u001b[39m(\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28mself\u001b[39m, documents: Sequence[Document]\n\u001b[1;32m    741\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[GraphDocument]:\n\u001b[1;32m    742\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a sequence of documents into graph documents.\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \n\u001b[1;32m    744\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;124;03m        Sequence[GraphDocument]: The transformed documents as graphs.\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response(document) \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m documents]\n",
      "File \u001b[0;32m~/anaconda3/envs/yolo/lib/python3.11/site-packages/langchain_experimental/graph_transformers/llm.py:703\u001b[0m, in \u001b[0;36mLLMGraphTransformer.process_response\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m    700\u001b[0m parsed_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjson_repair\u001b[38;5;241m.\u001b[39mloads(raw_schema)\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rel \u001b[38;5;129;01min\u001b[39;00m parsed_json:\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# Nodes need to be deduplicated using a set\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m     nodes_set\u001b[38;5;241m.\u001b[39madd((rel[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead\u001b[39m\u001b[38;5;124m\"\u001b[39m], rel[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    704\u001b[0m     nodes_set\u001b[38;5;241m.\u001b[39madd((rel[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtail\u001b[39m\u001b[38;5;124m\"\u001b[39m], rel[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtail_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    706\u001b[0m     source_node \u001b[38;5;241m=\u001b[39m Node(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mrel[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mrel[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_type\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'head'"
     ]
    }
   ],
   "source": [
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[0].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[0].relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpt4all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NVIDIA GeForce GTX 1080 Ti', 'NVIDIA GeForce GTX 1080 Ti (2)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA GeForce GTX 1080 Ti', major=6, minor=1, total_memory=11163MB, multi_processor_count=28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = chromadb.PersistentClient(path='../data/vectorstore/chromadb_512_32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = db.get_collection('langchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432889"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instructions: \n",
      "Based on the provided context, select the correct answer from the choices given. Provide your answer in the following format: option Number: Answer.\n",
      "\n",
      "Context:\n",
      "According to the provided context, when a UE supports slice-aware cell reselection and the NAS provides NSAG information and their priorities for consideration during cell reselection, the UE provides this information to the AS.<|eot_id|>\n",
      "\n",
      "Question:\n",
      "What does the UE provide to the AS for slice aware cell reselection? [3GPP Release 17]\n",
      "Choices:\n",
      "option 1: Slice-Maximum Bit Rate\n",
      "option 2: S-NSSAI\n",
      "option 3: NSSRG\n",
      "option 4: S-MBR\n",
      "option 5: NSAG information\n",
      "\n",
      "### Answer:\n"
     ]
    }
   ],
   "source": [
    "with open('../bin/pickle/inference_training_prompt.pkl','r+b') as f:\n",
    "    prompt = pickle.load(f)\n",
    "print(prompt[-4][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../bin/pickle/training_finetuning_prompt.pkl','r+b') as f:\n",
    "    prompt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instructions: \n",
      "Based on the provided context, select the correct answer from the choices given. Provide your answer in the following format: option Number: Answer.\n",
      "\n",
      "Context:\n",
      "-\tPRB usage (per cell: UL/DL). . NGAP procedures used for inter-system load balancing are Uplink RAN Configuration Transfer and Downlink RAN Configuration Transfer.. . S1AP procedures used for inter-system load balancing are eNB Configuration Transfer and MME Configuration Transfer.. . 2-step RACH optimization -\tNumber of active UEs;. . -\tRadio Resource Status (per cell PRB usage: UL/DL GBR PRB usage for MIMO, DL/UL non-GBR PRB usage for MIMO, DL/UL total PRB usage for MIMO).. . NGAP procedures used for inter-system load balancing are Uplink RAN Configuration Transfer and Downlink RAN Configuration Transfer. NGAP procedures used for inter-system load balancing are Uplink RAN Configuration Transfer and Downlink RAN Configuration Transfer.. . S1AP procedures used for inter-system load balancing are eNB Configuration Transfer and MME Configuration Transfer.. . 22.4.1.3\tLoad balancing action based on handovers\n",
      "\n",
      "Question:\n",
      "Which NGAP procedure is used for inter-system load balancing? [3GPP Release 17]\n",
      "Choices:\n",
      "option 1: eNB Configuration Transfer\n",
      "option 2: Downlink RAN Configuration Transfer\n",
      "option 3: Uplink RAN Configuration Transfer\n",
      "option 4: MME Configuration Transfer\n",
      "\n",
      "### Answer:\n",
      "option 3: Uplink RAN Configuration Transfer\n",
      "### Explanation:\n",
      "The NGAP procedure used for inter-system load balancing is Uplink RAN Configuration Transfer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt[8]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
