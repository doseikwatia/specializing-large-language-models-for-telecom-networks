---
common: 
  llm_model: 
    name: 'microsoft/phi-2'
    context_length: 2048
  embedding_model: 
    name: 'all-MiniLM-L6-v2.gguf2.f16.gguf'
    kwargs: 
      allow_download: True
  reranker_model: 'BAAI/bge-reranker-base'
  vectorstore:
    path: 'data/vectorstore/chromadb_512_32_all-MiniLM-L6-v2'
    #host and port are only used for ingest
    host: 'localhost'  
    port: -8000  
    k : 100
  compression_retriever_top_n: 2
  trained_model_dir: 'bin/driver-pretrained/'

data-ingest:
  n_jobs: 24
  index_chunk: 64
  textsplitter:
    chunk_size: 512
    overlap: 32
  documents: 
    path: 'data/rel18/'
    extensions: 
      - '*.docx'

training:
  epochs: 3
  n_jobs: 4
  lora_rank: 16
  learning_rate: 0.001
  output_dir: 'bin/'
  prompt_bin_filename: 'bin/pickle/driver_finetuning_datalist.pkl'
  data_filename: 'data/TeleQnA_training.txt'
  dataset_dir: 'data/driver-finetuning/'
  
 inference:
    task: Phi-2
    data_filename: 'data/TeleQnA_training.txt'
    outpu
  
