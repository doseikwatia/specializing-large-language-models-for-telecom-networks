---
common: 
  llm_model: 
    name: 'microsoft/phi-2'
    context_length: 2048
  embedding_model: 
    name: 'all-MiniLM-L6-v2.gguf2.f16.gguf'
    dimensionality: 384
    kwargs: 
      allow_download: True                          # Uncomment when using  all-MiniLM-L6-v2.gguf2.f16.gguf
  reranker_model: 'BAAI/bge-reranker-base'
  vectorstore:
    path:
    #host and port are only used for ingest
    host: 'localhost'  
    port: 8000  
    k : 200   #50-training, 200-testing
  compression_retriever_top_n: 5   #1 for fine tunning , 5 for inference
  trained_model_dir: 'bin/driver-all-MiniLM-L6-v2'

data-ingest:
  n_jobs: 8
  index_chunk: 256
  textsplitter:
    chunk_size: 512
    overlap: 150
  documents: 
    path: 'data/rel18/'
    extensions: 
      - '*.docx'

training:
  epochs: 6
  max_steps: -1
  n_jobs: 4
  lora_rank: 8
  learning_rate: 0.00005
  output_dir: 'bin/'
  prompt_bin_filename: 'bin/pickle/training_finetuning_prompt.pkl'
  data_filename: 'data/TeleQnA_training.txt'
  dataset_dir: 'data/driver-finetuning/'
  
inference:
    task: Phi-2
    run_mode: 1 #0- training only , 1-test only, 2- both train and test
    n_jobs: 4
    training_input_filename: 'data/TeleQnA_training.txt'
    testing_input_filename:  'data/Question_Submission.txt'
    training_output_filename: 'data/training_result.csv'
    testing_output_filename:  'data/testing_result_all-MiniLM-L6-v2_512_150.csv'
    training_prompt_bin_filename: 'bin/pickle/inference_training_prompt.pkl'
    testing_prompt_bin_filename: 'bin/pickle/inference_testing_prompt.pkl'
    training_results:  'data/Q_A_ID_training.csv'